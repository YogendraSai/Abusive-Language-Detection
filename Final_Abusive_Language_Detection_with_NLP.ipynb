{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUOSHR9MYwUj"
      },
      "source": [
        "<a id='1'></a>\n",
        "# <p style=\"background-color:violet; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 10px 25px;\">Importing necessary modules and librariesüìö</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QrtHzEzZYJL",
        "outputId": "14376d66-50c7-4d6f-a884-c53fe3ce369d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"
          ]
        }
      ],
      "source": [
        "pip install transformers nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IA9N4QbYwUr",
        "outputId": "dd6185d4-1713-4fdb-a588-fdd04353b865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk \n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# Load Huggingface transformers\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast, TFAutoModel\n",
        "\n",
        "# Then what you need from tensorflow.keras\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import re,string,unicodedata\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Convert text into vectors using TF-IDF\n",
        "# 2. Instantiate MultinomialNB classifier\n",
        "# 3. Split feature and label\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "stopwords = nltk.download('stopwords')\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "# model save & load\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mi7hFMzeNZn",
        "outputId": "68157d5a-b62d-4ea3-d3a0-d8c70b91fb86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFODSsY3YwUz"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Project 5800/Dataset_Abusive_Non-Abusive.csv',nrows=1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTkW3HZZxyU5"
      },
      "outputs": [],
      "source": [
        "def showBar(trump, musk, title):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_axes([0,0,1,1])\n",
        "  height = [trump, musk]\n",
        "  bars = ('Trump - ' + str(trump), 'Musk - ' + str(musk))\n",
        "  x_pos = np.arange(len(bars))\n",
        "  plt.title(title)\n",
        "  plt.bar(x_pos, height, color=[ 'red', 'blue'])\n",
        "  plt.xticks(x_pos, bars)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NNlY5fSx68R"
      },
      "outputs": [],
      "source": [
        "def saveModel(model, modelName):\n",
        "  pickle.dump(model, open(modelName + '.sav', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbwo3sYAx7Wm"
      },
      "outputs": [],
      "source": [
        "def loadModel(modelName):\n",
        "  return pickle.load(open(modelName + '.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = set(\",.:;'‚Äô\\\"-?_!/()¬¥`%@#&$*\")\n",
        "def removePunctuation(txt):\n",
        "   return ''.join([(c if c not in exclude else \" \") for c in txt])\n",
        "    \n",
        "def removeNumbers(txt):\n",
        "    return ''.join(c for c in txt if not c.isnumeric())\n",
        "\n",
        "def removeStopwords(txt):\n",
        "    return ' '.join(w for w in word_tokenize(txt) if not w.lower() in stop_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xn5MeS9CtkkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKeII5gEYwVt"
      },
      "source": [
        "::Let's remove numbers first and assign cleaned data to new column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSazH-VFYwVu"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df['cleaned'] = train_df['tweet'].apply(lambda x: removePunctuation(x))\n",
        "train_df['cleaned'] = train_df['cleaned'].apply(lambda x: removeNumbers(x))\n",
        "train_df['cleaned'] = train_df['cleaned'].apply(lambda x: removeStopwords(x))\n",
        "train_df['cleaned'] = train_df['cleaned'].apply(lambda x: removePunctuation(x))\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = train_df['cleaned'], train_df['Abusive']\n",
        
        "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
        "vectoriser.fit(X_train)\n",
        "X_train = vectoriser.transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRkh7_IlYwVv"
      },
      "source": [
        "Okay, we can see now punctuations have been removed from the comments. As a second step, let's remove numbers and assign cleaned data to new column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "L9YzM2kOYwVw",
        "outputId": "3eb85d32-e679-445a-92cc-6d250d48d568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Abusive  Non_Abusive  \\\n",
              "0        0            1   \n",
              "1        1            0   \n",
              "2        1            0   \n",
              "3        1            0   \n",
              "4        1            0   \n",
              "5        1            0   \n",
              "6        1            0   \n",
              "7        1            0   \n",
              "8        1            0   \n",
              "9        1            0   \n",
              "\n",
              "                                                                                                 tweet  \\\n",
              "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a...   \n",
              "1                !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
              "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...   \n",
              "3                                       !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
              "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...   \n",
              "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for some...   \n",
              "6  !!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit g...   \n",
              "7   !!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;   \n",
              "8                                           \" &amp; you might not get ya bitch back &amp; thats that \"   \n",
              "9                                            \" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch   \n",
              "\n",
              "                                                                      cleaned  \n",
              "0     RT mayasolovely woman complain cleaning house amp man always take trash  \n",
              "1                 RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place  \n",
              "2  RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit  \n",
              "3                                 RT C G Anderson viva based look like tranny  \n",
              "4            RT ShenikaRoberts shit hear might true might faker bitch told ya  \n",
              "5             Madison x shit blows claim faithful somebody still fucking hoes  \n",
              "6                     BrighterDays sit HATE another bitch got much shit going  \n",
              "7               selfiequeenbri cause tired big bitches coming us skinny girls  \n",
              "8                                       amp might get ya bitch back amp thats  \n",
              "9                             rhythmixx hobbies include fighting Mariam bitch  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5833c754-273c-43a6-a1c5-b7bf7ac21882\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abusive</th>\n",
              "      <th>Non_Abusive</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a...</td>\n",
              "      <td>RT mayasolovely woman complain cleaning house amp man always take trash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
              "      <td>RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...</td>\n",
              "      <td>RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
              "      <td>RT C G Anderson viva based look like tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...</td>\n",
              "      <td>RT ShenikaRoberts shit hear might true might faker bitch told ya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for some...</td>\n",
              "      <td>Madison x shit blows claim faithful somebody still fucking hoes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit g...</td>\n",
              "      <td>BrighterDays sit HATE another bitch got much shit going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&amp;#8221;</td>\n",
              "      <td>selfiequeenbri cause tired big bitches coming us skinny girls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; thats that \"</td>\n",
              "      <td>amp might get ya bitch back amp thats</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>\" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch</td>\n",
              "      <td>rhythmixx hobbies include fighting Mariam bitch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5833c754-273c-43a6-a1c5-b7bf7ac21882')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5833c754-273c-43a6-a1c5-b7bf7ac21882 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5833c754-273c-43a6-a1c5-b7bf7ac21882');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_df['cleaned'] = train_df['cleaned'].apply(lambda x: removeNumbers(x))\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow6BJmvDYwVy"
      },
      "source": [
        "Removing Stop Words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TLdgzIqYwVy",
        "outputId": "29860c5c-45dc-4464-adf1-903f37caaea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "stopwords = nltk.download('stopwords')\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGTgXBetYwWA"
      },
      "outputs": [],
      "source": [
        "import re,string,unicodedata\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 1. Convert text into vectors using TF-IDF\n",
        "# 2. Instantiate MultinomialNB classifier\n",
        "# 3. Split feature and label\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_2LZS8QYwWA"
      },
      "source": [
        "<a id=\"#\"></a>\n",
        "    \n",
        "<font size=\"+2\" color=\"indigo\"><b>BERT</b></font><br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWSMAmnsYwWB",
        "outputId": "af893408-bf7b-4dc8-cf45-ddfb54a10c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# Name of the BERT model to use\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# Max length of tokens\n",
        "max_length = 40\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "#config.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "bert = TFAutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_bMPqMvYwWB"
      },
      "outputs": [],
      "source": [
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') \n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "x = bert.bert(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koT7zyeLYwWB",
        "outputId": "d9dbfb65-a196-4e1e-c777-ce8ddca5a0f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 40, 768) dtype=float32 (created by layer 'bert')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zo0yCmbdYwWC",
        "outputId": "edb961fa-c226-452b-c279-672a31f5cc8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT ShenikaRoberts shit hear might true might faker bitch told ya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "train_df.cleaned[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ChpksEzYYwWF",
        "outputId": "42a03b26-8143-40a6-862e-c51c851e651d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Non_Abusive  \\\n",
              "0               1   \n",
              "1               0   \n",
              "2               0   \n",
              "3               0   \n",
              "4               0   \n",
              "...           ...   \n",
              "1495            0   \n",
              "1496            1   \n",
              "1497            0   \n",
              "1498            0   \n",
              "1499            0   \n",
              "\n",
              "                                                                                                    tweet  \\\n",
              "0     !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a...   \n",
              "1                   !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
              "2     !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...   \n",
              "3                                          !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
              "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...   \n",
              "...                                                                                                   ...   \n",
              "1495                                           &#8220;@RudeBoi_Drew: I'm finna eat some pussy&#8221; lmao   \n",
              "1496  &#8220;@RudeNation21: When girls take my snap backs and beanies lol&#128169; that's 35 dollars a...   \n",
              "1497  &#8220;@RudePost: A new breed of white girl... https://t.co/0Zsu3zQiXD&#8221; she slammed that b...   \n",
              "1498  &#8220;@Runyacheckup: &#8220;@Shane_A1: A Bitch Couldn't pay me to get dem pregnant again &#1285...   \n",
              "1499  &#8220;@RyeOrDie: Niggas want pussy. I ain't giving any out. Here is where lies our dilemma.&#82...   \n",
              "\n",
              "                                                                              cleaned  \\\n",
              "0             RT mayasolovely woman complain cleaning house amp man always take trash   \n",
              "1                         RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place   \n",
              "2          RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit   \n",
              "3                                         RT C G Anderson viva based look like tranny   \n",
              "4                    RT ShenikaRoberts shit hear might true might faker bitch told ya   \n",
              "...                                                                               ...   \n",
              "1495                                                RudeBoi Drew finna eat pussy lmao   \n",
              "1496     RudeNation girls take snap backs beanies lol dollars hat AX beanieS let take   \n",
              "1497                    RudePost new breed white girl https co ZsuzQiXD slammed bitch   \n",
              "1498  Runyacheckup Shane Bitch pay get dem pregnant fr fam ion see niccas poppin kids   \n",
              "1499                              RyeOrDie Niggas want pussy giving lies dilemma cool   \n",
              "\n",
              "      Abusive_0  Abusive_1  \n",
              "0             1          0  \n",
              "1             0          1  \n",
              "2             0          1  \n",
              "3             0          1  \n",
              "4             0          1  \n",
              "...         ...        ...  \n",
              "1495          0          1  \n",
              "1496          1          0  \n",
              "1497          0          1  \n",
              "1498          0          1  \n",
              "1499          0          1  \n",
              "\n",
              "[1500 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-552eb720-6907-4092-9ea6-44e76b715fc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Non_Abusive</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>Abusive_0</th>\n",
              "      <th>Abusive_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a...</td>\n",
              "      <td>RT mayasolovely woman complain cleaning house amp man always take trash</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
              "      <td>RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...</td>\n",
              "      <td>RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
              "      <td>RT C G Anderson viva based look like tranny</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...</td>\n",
              "      <td>RT ShenikaRoberts shit hear might true might faker bitch told ya</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RudeBoi_Drew: I'm finna eat some pussy&amp;#8221; lmao</td>\n",
              "      <td>RudeBoi Drew finna eat pussy lmao</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#8220;@RudeNation21: When girls take my snap backs and beanies lol&amp;#128169; that's 35 dollars a...</td>\n",
              "      <td>RudeNation girls take snap backs beanies lol dollars hat AX beanieS let take</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RudePost: A new breed of white girl... https://t.co/0Zsu3zQiXD&amp;#8221; she slammed that b...</td>\n",
              "      <td>RudePost new breed white girl https co ZsuzQiXD slammed bitch</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@Runyacheckup: &amp;#8220;@Shane_A1: A Bitch Couldn't pay me to get dem pregnant again &amp;#1285...</td>\n",
              "      <td>Runyacheckup Shane Bitch pay get dem pregnant fr fam ion see niccas poppin kids</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RyeOrDie: Niggas want pussy. I ain't giving any out. Here is where lies our dilemma.&amp;#82...</td>\n",
              "      <td>RyeOrDie Niggas want pussy giving lies dilemma cool</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows √ó 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-552eb720-6907-4092-9ea6-44e76b715fc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-552eb720-6907-4092-9ea6-44e76b715fc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-552eb720-6907-4092-9ea6-44e76b715fc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df_la = pd.get_dummies(train_df, columns = ['Abusive'])\n",
        "df_la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AFQ1L_CYwWH"
      },
      "outputs": [],
      "source": [
        "train_sentences = train_df[\"cleaned\"].values\n",
        "list_classes = ['Abusive_0','Abusive_1']\n",
        "train_y = df_la[list_classes].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYP8vWucYwWI",
        "outputId": "ff1fa1af-3eff-46f9-a05a-5a4107a5f12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer)    [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)         [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['attention_mask[0][0]',         \n",
            "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 40,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 768)         0           ['bert[0][0]']                   \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            1538        ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#x2 =Dense(512, activation='relu')(x[1])\n",
        "x2 = GlobalAveragePooling1D()(x[0])\n",
        "#x3 = Dropout(0.5)(x2)\n",
        "y =Dense(len(list_classes), activation='sigmoid', name='outputs')(x2)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=y)\n",
        "#model.layers[2].trainable = False\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvN3a3GLYwWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5787d5a0-23e1-4eb8-abbd-3d63f72da159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(lr=1e-5)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tEaXWh9YwWK"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input \n",
        "x = tokenizer(\n",
        "    text=list(train_sentences),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxMJuMQQYwWL",
        "outputId": "864de15c-bea0-4fce-aff7-39f2ba8a48bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43/43 [==============================] - 86s 444ms/step - loss: 0.6100 - accuracy: 0.7815 - val_loss: 0.2985 - val_accuracy: 0.9133\n",
            "Epoch 2/3\n",
            "43/43 [==============================] - 14s 328ms/step - loss: 0.4497 - accuracy: 0.8363 - val_loss: 0.3190 - val_accuracy: 0.9133\n",
            "Epoch 3/3\n",
            "43/43 [==============================] - 14s 329ms/step - loss: 0.4491 - accuracy: 0.8363 - val_loss: 0.3069 - val_accuracy: 0.9133\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    #x={'input_ids': x['input_ids']},\n",
        "    y={'outputs': train_y},\n",
        "    validation_split=0.1,\n",
        "    #batch_size=45,\n",
        "    epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveModel(bert, 'bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aySIgXqyxBZc",
        "outputId": "f13b9d28-9e11-4b06-d9c5-0518ea074cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
            "...bert\n",
            "......embeddings\n",
            ".........LayerNorm\n",
            "............vars\n",
            "...............0\n",
            "...............1\n",
            ".........dropout\n",
            "............vars\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "............2\n",
            "......encoder\n",
            ".........layer\n",
            "............tf_bert_layer\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_1\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_10\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_11\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_2\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_3\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_4\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_5\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_6\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_7\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_8\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            "............tf_bert_layer_9\n",
            "...............attention\n",
            "..................dense_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................self_attention\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................key\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................query\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................value\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............bert_output\n",
            "..................LayerNorm\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................vars\n",
            "...............intermediate\n",
            "..................dense\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............vars\n",
            ".........vars\n",
            "......pooler\n",
            ".........dense\n",
            "............vars\n",
            "...............0\n",
            "...............1\n",
            ".........vars\n",
            "......vars\n",
            "...vars\n",
            "Keras model archive saving:\n",
            "File Name                                             Modified             Size\n",
            "variables.h5                                   2023-03-27 22:41:15    438388032\n",
            "config.json                                    2023-03-27 22:41:13         2031\n",
            "metadata.json                                  2023-03-27 22:41:13           64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa"
      ],
      "metadata": {
        "id": "23YiKqwUY1NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig\n",
        "from transformers import RobertaConfig, RobertaModel"
      ],
      "metadata": {
        "id": "70DjDTFjahnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the BERT model to use\n",
        "model_name = 'roberta-base'\n",
        "\n",
        "# Max length of tokens\n",
        "max_length = 40\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "#config = BertConfig.from_pretrained(model_name)\n",
        "configuration = RobertaConfig()\n",
        "#config.output_hidden_states = False\n",
        "model = RobertaModel(configuration)\n",
        "configuration = model.config\n",
        "# Load BERT tokenizer\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta = TFAutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijYrowl8Y9FS",
        "outputId": "8075906d-b19f-4443-c57d-14c5b184a21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') \n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "x = roberta.roberta(inputs)"
      ],
      "metadata": {
        "id": "1oGfBftLamfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lva5ej5115D",
        "outputId": "ef34cc5d-52c7-4152-fcc3-e87bea0e6311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 40, 768) dtype=float32 (created by layer 'roberta')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'roberta')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.cleaned[4]"
      ],
      "metadata": {
        "id": "k4V0P2sVaowu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e891fd92-6d81-4d36-9f5d-3e917e4a73e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT ShenikaRoberts shit hear might true might faker bitch told ya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_la = pd.get_dummies(train_df, columns = ['Abusive'])\n",
        "df_la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "t7rGXOk4mT3Z",
        "outputId": "45770670-ffdd-4c95-ba54-fcc8b6331e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Non_Abusive  \\\n",
              "0               1   \n",
              "1               0   \n",
              "2               0   \n",
              "3               0   \n",
              "4               0   \n",
              "...           ...   \n",
              "1495            0   \n",
              "1496            1   \n",
              "1497            0   \n",
              "1498            0   \n",
              "1499            0   \n",
              "\n",
              "                                                                                                    tweet  \\\n",
              "0     !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a...   \n",
              "1                   !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
              "2     !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...   \n",
              "3                                          !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
              "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...   \n",
              "...                                                                                                   ...   \n",
              "1495                                           &#8220;@RudeBoi_Drew: I'm finna eat some pussy&#8221; lmao   \n",
              "1496  &#8220;@RudeNation21: When girls take my snap backs and beanies lol&#128169; that's 35 dollars a...   \n",
              "1497  &#8220;@RudePost: A new breed of white girl... https://t.co/0Zsu3zQiXD&#8221; she slammed that b...   \n",
              "1498  &#8220;@Runyacheckup: &#8220;@Shane_A1: A Bitch Couldn't pay me to get dem pregnant again &#1285...   \n",
              "1499  &#8220;@RyeOrDie: Niggas want pussy. I ain't giving any out. Here is where lies our dilemma.&#82...   \n",
              "\n",
              "                                                                              cleaned  \\\n",
              "0             RT mayasolovely woman complain cleaning house amp man always take trash   \n",
              "1                         RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place   \n",
              "2          RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit   \n",
              "3                                         RT C G Anderson viva based look like tranny   \n",
              "4                    RT ShenikaRoberts shit hear might true might faker bitch told ya   \n",
              "...                                                                               ...   \n",
              "1495                                                RudeBoi Drew finna eat pussy lmao   \n",
              "1496     RudeNation girls take snap backs beanies lol dollars hat AX beanieS let take   \n",
              "1497                    RudePost new breed white girl https co ZsuzQiXD slammed bitch   \n",
              "1498  Runyacheckup Shane Bitch pay get dem pregnant fr fam ion see niccas poppin kids   \n",
              "1499                              RyeOrDie Niggas want pussy giving lies dilemma cool   \n",
              "\n",
              "      Abusive_0  Abusive_1  \n",
              "0             1          0  \n",
              "1             0          1  \n",
              "2             0          1  \n",
              "3             0          1  \n",
              "4             0          1  \n",
              "...         ...        ...  \n",
              "1495          0          1  \n",
              "1496          1          0  \n",
              "1497          0          1  \n",
              "1498          0          1  \n",
              "1499          0          1  \n",
              "\n",
              "[1500 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-044314c0-c010-43a0-b841-4cc4eeb71f3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Non_Abusive</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>Abusive_0</th>\n",
              "      <th>Abusive_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a...</td>\n",
              "      <td>RT mayasolovely woman complain cleaning house amp man always take trash</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
              "      <td>RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...</td>\n",
              "      <td>RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
              "      <td>RT C G Anderson viva based look like tranny</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...</td>\n",
              "      <td>RT ShenikaRoberts shit hear might true might faker bitch told ya</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RudeBoi_Drew: I'm finna eat some pussy&amp;#8221; lmao</td>\n",
              "      <td>RudeBoi Drew finna eat pussy lmao</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#8220;@RudeNation21: When girls take my snap backs and beanies lol&amp;#128169; that's 35 dollars a...</td>\n",
              "      <td>RudeNation girls take snap backs beanies lol dollars hat AX beanieS let take</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RudePost: A new breed of white girl... https://t.co/0Zsu3zQiXD&amp;#8221; she slammed that b...</td>\n",
              "      <td>RudePost new breed white girl https co ZsuzQiXD slammed bitch</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@Runyacheckup: &amp;#8220;@Shane_A1: A Bitch Couldn't pay me to get dem pregnant again &amp;#1285...</td>\n",
              "      <td>Runyacheckup Shane Bitch pay get dem pregnant fr fam ion see niccas poppin kids</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RyeOrDie: Niggas want pussy. I ain't giving any out. Here is where lies our dilemma.&amp;#82...</td>\n",
              "      <td>RyeOrDie Niggas want pussy giving lies dilemma cool</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows √ó 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-044314c0-c010-43a0-b841-4cc4eeb71f3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-044314c0-c010-43a0-b841-4cc4eeb71f3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-044314c0-c010-43a0-b841-4cc4eeb71f3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_df[\"cleaned\"].values\n",
        "list_classes = ['Abusive_0','Abusive_1']\n",
        "train_y = df_la[list_classes].values"
      ],
      "metadata": {
        "id": "hKSsUTAOmTqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 =Dense(512, activation='relu')(x[1])\n",
        "#x2 = GlobalAveragePooling1D()([0])\n",
        "#x3 = Dropout(0.5)(x2)\n",
        "y =Dense(len(list_classes), activation='sigmoid', name='outputs')(x2)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=y)\n",
        "#model.layers[2].trainable = False\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HK8WZYBmTkB",
        "outputId": "1f1140bd-9439-4983-c451-c626ed0593e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer)    [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)         [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " roberta (TFRobertaMainLayer)   TFBaseModelOutputWi  124645632   ['attention_mask[0][0]',         \n",
            "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 40,                                                \n",
            "                                768),                                                             \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['roberta[0][1]']                \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            1026        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125,040,386\n",
            "Trainable params: 125,040,386\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(learning_rate=0.001, weight_decay=None)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rN_BS2Si1A6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tokenizer(\n",
        "    text=list(train_sentences),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "-_CqiPDpjQLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    #x={'input_ids': x['input_ids']},\n",
        "    y={'outputs': train_y},\n",
        "    validation_split=0.1,\n",
        "    #batch_size=45,\n",
        "    epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWPXeZEDKxoP",
        "outputId": "27dd42ae-6a6f-40e1-fc55-2166f7891bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "43/43 [==============================] - 64s 457ms/step - loss: 0.5103 - accuracy: 0.8304 - val_loss: 0.3155 - val_accuracy: 0.9133\n",
            "Epoch 2/3\n",
            "43/43 [==============================] - 14s 327ms/step - loss: 0.4552 - accuracy: 0.8363 - val_loss: 0.3214 - val_accuracy: 0.9133\n",
            "Epoch 3/3\n",
            "43/43 [==============================] - 14s 318ms/step - loss: 0.4595 - accuracy: 0.8363 - val_loss: 0.2955 - val_accuracy: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveModel(roberta, 'roberta')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqfAJ3_jxLWu",
        "outputId": "750d581a-8207-4299-8f10-e62581cd012b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
            "...layers\n",
            "......tf_roberta_main_layer\n",
            ".........embeddings\n",
            "............LayerNorm\n",
            "...............vars\n",
            "..................0\n",
            "..................1\n",
            "............dropout\n",
            "...............vars\n",
            "............vars\n",
            "...............0\n",
            "...............1\n",
            "...............2\n",
            ".........encoder\n",
            "............layer\n",
            "...............tf_roberta_layer\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_1\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_10\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_11\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_2\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_3\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_4\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_5\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_6\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_7\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_8\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "...............tf_roberta_layer_9\n",
            "..................attention\n",
            ".....................dense_output\n",
            "........................LayerNorm\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dense\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................vars\n",
            ".....................self_attention\n",
            "........................dropout\n",
            "...........................vars\n",
            "........................key\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................query\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................value\n",
            "...........................vars\n",
            "..............................0\n",
            "..............................1\n",
            "........................vars\n",
            ".....................vars\n",
            "..................bert_output\n",
            ".....................LayerNorm\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................dropout\n",
            "........................vars\n",
            ".....................vars\n",
            "..................intermediate\n",
            ".....................dense\n",
            "........................vars\n",
            "...........................0\n",
            "...........................1\n",
            ".....................vars\n",
            "..................vars\n",
            "............vars\n",
            ".........pooler\n",
            "............dense\n",
            "...............vars\n",
            "..................0\n",
            "..................1\n",
            "............vars\n",
            ".........vars\n",
            "...vars\n",
            "Keras model archive saving:\n",
            "File Name                                             Modified             Size\n",
            "variables.h5                                   2023-03-27 22:43:05    499042632\n",
            "config.json                                    2023-03-27 22:43:03         2005\n",
            "metadata.json                                  2023-03-27 22:43:03           64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DisitlBERT"
      ],
      "metadata": {
        "id": "UcFw1AM7_nN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "from transformers import DistilBertConfig, DistilBertModel"
      ],
      "metadata": {
        "id": "kScGlYdE_mzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the BERT model to use\n",
        "model_name = 'distilbert-base-uncased'\n",
        "\n",
        "# Max length of tokens\n",
        "max_length = 40\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "#config = BertConfig.from_pretrained(model_name)\n",
        "configuration = DistilBertConfig()\n",
        "#config.output_hidden_states = False\n",
        "model = DistilBertModel(configuration)\n",
        "configuration = model.config\n",
        "# Load BERT tokenizer\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert= TFAutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcbvTpcQ_miy",
        "outputId": "f5f16ae5-a037-44c8-ab89-c81fe778b33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'activation_13', 'vocab_transform', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') \n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "x = distilbert.distilbert(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dLUdC5h_mWt",
        "outputId": "7259a29b-fdbd-4758-dbbb-a4a2c2339a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz3h_mtI_mLO",
        "outputId": "24b64286-f1ee-4d48-f772-43af77130f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutput(last_hidden_state=<KerasTensor: shape=(None, 40, 768) dtype=float32 (created by layer 'distilbert')>, hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_la = pd.get_dummies(train_df, columns = ['Abusive'])\n",
        "df_la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Ky4uEz4w_mBK",
        "outputId": "bee2b02b-a601-4ba0-e574-5a962d6967ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Non_Abusive  \\\n",
              "0               1   \n",
              "1               0   \n",
              "2               0   \n",
              "3               0   \n",
              "4               0   \n",
              "...           ...   \n",
              "1495            0   \n",
              "1496            1   \n",
              "1497            0   \n",
              "1498            0   \n",
              "1499            0   \n",
              "\n",
              "                                                                                                    tweet  \\\n",
              "0     !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a...   \n",
              "1                   !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
              "2     !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...   \n",
              "3                                          !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
              "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...   \n",
              "...                                                                                                   ...   \n",
              "1495                                           &#8220;@RudeBoi_Drew: I'm finna eat some pussy&#8221; lmao   \n",
              "1496  &#8220;@RudeNation21: When girls take my snap backs and beanies lol&#128169; that's 35 dollars a...   \n",
              "1497  &#8220;@RudePost: A new breed of white girl... https://t.co/0Zsu3zQiXD&#8221; she slammed that b...   \n",
              "1498  &#8220;@Runyacheckup: &#8220;@Shane_A1: A Bitch Couldn't pay me to get dem pregnant again &#1285...   \n",
              "1499  &#8220;@RyeOrDie: Niggas want pussy. I ain't giving any out. Here is where lies our dilemma.&#82...   \n",
              "\n",
              "                                                                              cleaned  \\\n",
              "0             RT mayasolovely woman complain cleaning house amp man always take trash   \n",
              "1                         RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place   \n",
              "2          RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit   \n",
              "3                                         RT C G Anderson viva based look like tranny   \n",
              "4                    RT ShenikaRoberts shit hear might true might faker bitch told ya   \n",
              "...                                                                               ...   \n",
              "1495                                                RudeBoi Drew finna eat pussy lmao   \n",
              "1496     RudeNation girls take snap backs beanies lol dollars hat AX beanieS let take   \n",
              "1497                    RudePost new breed white girl https co ZsuzQiXD slammed bitch   \n",
              "1498  Runyacheckup Shane Bitch pay get dem pregnant fr fam ion see niccas poppin kids   \n",
              "1499                              RyeOrDie Niggas want pussy giving lies dilemma cool   \n",
              "\n",
              "      Abusive_0  Abusive_1  \n",
              "0             1          0  \n",
              "1             0          1  \n",
              "2             0          1  \n",
              "3             0          1  \n",
              "4             0          1  \n",
              "...         ...        ...  \n",
              "1495          0          1  \n",
              "1496          1          0  \n",
              "1497          0          1  \n",
              "1498          0          1  \n",
              "1499          0          1  \n",
              "\n",
              "[1500 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84b9d760-f369-45e8-abc1-5414a492ea66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Non_Abusive</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>Abusive_0</th>\n",
              "      <th>Abusive_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a...</td>\n",
              "      <td>RT mayasolovely woman complain cleaning house amp man always take trash</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
              "      <td>RT mleew boy dats cold tyga dwn bad cuffin dat hoe st place</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry?...</td>\n",
              "      <td>RT UrKindOfBrand Dawg RT sbabylife ever fuck bitch start cry confused shit</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
              "      <td>RT C G Anderson viva based look like tranny</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker ...</td>\n",
              "      <td>RT ShenikaRoberts shit hear might true might faker bitch told ya</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RudeBoi_Drew: I'm finna eat some pussy&amp;#8221; lmao</td>\n",
              "      <td>RudeBoi Drew finna eat pussy lmao</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>1</td>\n",
              "      <td>&amp;#8220;@RudeNation21: When girls take my snap backs and beanies lol&amp;#128169; that's 35 dollars a...</td>\n",
              "      <td>RudeNation girls take snap backs beanies lol dollars hat AX beanieS let take</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RudePost: A new breed of white girl... https://t.co/0Zsu3zQiXD&amp;#8221; she slammed that b...</td>\n",
              "      <td>RudePost new breed white girl https co ZsuzQiXD slammed bitch</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@Runyacheckup: &amp;#8220;@Shane_A1: A Bitch Couldn't pay me to get dem pregnant again &amp;#1285...</td>\n",
              "      <td>Runyacheckup Shane Bitch pay get dem pregnant fr fam ion see niccas poppin kids</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>0</td>\n",
              "      <td>&amp;#8220;@RyeOrDie: Niggas want pussy. I ain't giving any out. Here is where lies our dilemma.&amp;#82...</td>\n",
              "      <td>RyeOrDie Niggas want pussy giving lies dilemma cool</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows √ó 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84b9d760-f369-45e8-abc1-5414a492ea66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84b9d760-f369-45e8-abc1-5414a492ea66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84b9d760-f369-45e8-abc1-5414a492ea66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_df[\"cleaned\"].values\n",
        "list_classes = ['Abusive_0','Abusive_1']\n",
        "train_y = df_la[list_classes].values"
      ],
      "metadata": {
        "id": "iq8OerFo_lyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x2 =Dense(512, activation='relu')(x[0])\n",
        "x2 = GlobalAveragePooling1D()(x[0])\n",
        "#x3 = Dropout(0.5)(x2)\n",
        "y =Dense(len(list_classes), activation='sigmoid', name='outputs')(x2)\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs=y)\n",
        "#model.layers[2].trainable = False\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWFXIR9T_lmn",
        "outputId": "d7be874e-ac22-4268-b3fa-4bb89fcd23d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer)    [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)         [(None, 40)]         0           []                               \n",
            "                                                                                                  \n",
            " distilbert (TFDistilBertMainLa  TFBaseModelOutput(l  66362880   ['attention_mask[0][0]',         \n",
            " yer)                           ast_hidden_state=(N               'input_ids[0][0]']              \n",
            "                                one, 40, 768),                                                    \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3 (Gl  (None, 768)         0           ['distilbert[0][0]']             \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            1538        ['global_average_pooling1d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,364,418\n",
            "Trainable params: 66,364,418\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(learning_rate=0.001, weight_decay=None)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T3rp6oGN_lV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tokenizer(\n",
        "    text=list(train_sentences),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "PeIOjQsqFpnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    #x={'input_ids': x['input_ids']},\n",
        "    y={'outputs': train_y},\n",
        "    validation_split=0.1,\n",
        "    #batch_size=45,\n",
        "    epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKHkTUCVFphi",
        "outputId": "82b2ec92-6cd7-4508-8eae-8e05f12ad7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "43/43 [==============================] - 33s 255ms/step - loss: 0.7454 - accuracy: 0.7970 - val_loss: 0.4189 - val_accuracy: 0.9133\n",
            "Epoch 2/3\n",
            "43/43 [==============================] - 8s 179ms/step - loss: 0.4588 - accuracy: 0.8363 - val_loss: 0.3320 - val_accuracy: 0.9133\n",
            "Epoch 3/3\n",
            "43/43 [==============================] - 8s 186ms/step - loss: 0.4503 - accuracy: 0.8363 - val_loss: 0.2958 - val_accuracy: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saveModel(distilbert, 'distilbert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGudFTfVxTgi",
        "outputId": "fdf1e355-d37e-4f9e-d6b8-5382598b9c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
            "...distilbert\n",
            "......embeddings\n",
            ".........LayerNorm\n",
            "............vars\n",
            "...............0\n",
            "...............1\n",
            ".........dropout\n",
            "............vars\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......transformer\n",
            ".........layer\n",
            "............tf_transformer_block\n",
            "...............attention\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................k_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................out_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................q_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................v_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............dropout\n",
            "..................vars\n",
            "...............ffn\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................lin1\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................lin2\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............output_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............sa_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............vars\n",
            "............tf_transformer_block_1\n",
            "...............attention\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................k_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................out_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................q_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................v_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............dropout\n",
            "..................vars\n",
            "...............ffn\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................lin1\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................lin2\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............output_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............sa_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............vars\n",
            "............tf_transformer_block_2\n",
            "...............attention\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................k_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................out_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................q_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................v_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............dropout\n",
            "..................vars\n",
            "...............ffn\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................lin1\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................lin2\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............output_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............sa_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............vars\n",
            "............tf_transformer_block_3\n",
            "...............attention\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................k_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................out_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................q_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................v_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............dropout\n",
            "..................vars\n",
            "...............ffn\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................lin1\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................lin2\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............output_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............sa_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............vars\n",
            "............tf_transformer_block_4\n",
            "...............attention\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................k_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................out_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................q_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................v_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............dropout\n",
            "..................vars\n",
            "...............ffn\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................lin1\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................lin2\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............output_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............sa_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............vars\n",
            "............tf_transformer_block_5\n",
            "...............attention\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................k_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................out_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................q_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................v_lin\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............dropout\n",
            "..................vars\n",
            "...............ffn\n",
            "..................dropout\n",
            ".....................vars\n",
            "..................lin1\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................lin2\n",
            ".....................vars\n",
            "........................0\n",
            "........................1\n",
            "..................vars\n",
            "...............output_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............sa_layer_norm\n",
            "..................vars\n",
            ".....................0\n",
            ".....................1\n",
            "...............vars\n",
            ".........vars\n",
            "......vars\n",
            "...vars\n",
            "Keras model archive saving:\n",
            "File Name                                             Modified             Size\n",
            "variables.h5                                   2023-03-27 22:44:13    265655296\n",
            "config.json                                    2023-03-27 22:44:12         1947\n",
            "metadata.json                                  2023-03-27 22:44:12           64\n"
          ]
        }
      ]
    },
    
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "papermill": {
      "duration": 980.002764,
      "end_time": "2021-09-08T10:39:16.416973",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-09-08T10:22:56.414209",
      "version": "2.1.0"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

